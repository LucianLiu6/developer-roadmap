<div data-github-url="https://github.com/kamranahmedse/developer-roadmap/tree/master/src/data/roadmaps/prompt-engineering/content/106-llm-settings/100-temperature.md"></div> <h1 id="temperature">Temperature</h1>
<p>Temperature is an important setting in the Language Models (LMs), specifically for the fine-tuning process. It refers to the “temperature” parameter in the softmax function of the language model. Adjusting the temperature can influence the randomness or conservativeness of the model’s output.</p>
<h2 id="role-of-temperature">Role of Temperature</h2>
<p>The temperature controls the model’s level of creativity and boldness in generating text. A lower temperature value makes the model more conservative, sticking closely to the patterns it has learned from the training data. Higher temperature values encourage the model to explore riskier solutions by allowing less likely tokens to be more probable.</p>
<h2 id="practical-uses">Practical Uses</h2>
<p>When fine-tuning an LM, you can regulate its behavior by adjusting the temperature:</p>
<ul>
<li>
<p><strong>Lower temperature values</strong> (e.g., 0.2 or 0.5): The model will be more focused on phrases and word sequences that it learned from the training data. The output will be less diverse, but may lack novelty or creativity. Suitable for tasks where conservativeness is important, such as text summarization or translation.</p>
</li>
<li>
<p><strong>Higher temperature values</strong> (e.g., 1.0 or 2.0): The model will generate more creative outputs with innovative combinations of words. However, it may produce less coherent or contextually improper text. Useful for tasks where exploration and distinctiveness are required, like creative writing or brainstorming.</p>
</li>
</ul>
<p>Experimenting with various temperature values can lead to finding the optimal balance between creativity and coherence, depending on the specific task and desired output.</p>